*vocal.txt*  Speech-to-text transcription using OpenAI Whisper API

===============================================================================
CONTENTS                                                          *vocal-contents*

    1. Introduction .................... |vocal-introduction|
    2. Requirements .................... |vocal-requirements|
    3. Installation .................... |vocal-installation|
    4. Configuration ................... |vocal-configuration|
    5. Usage ........................... |vocal-usage|
    6. Commands ........................ |vocal-commands|
    7. API Configuration ............... |vocal-api-config|
    8. Troubleshooting ................. |vocal-troubleshooting|
    9. License ......................... |vocal-license|

===============================================================================
1. INTRODUCTION                                               *vocal-introduction*

vocal.nvim is a lightweight Neovim plugin that provides speech-to-text
functionality using the OpenAI Whisper API. It enables users to record audio
directly within Neovim, send it to the OpenAI Whisper API for transcription,
and insert the transcribed text into the current buffer.

===============================================================================
2. REQUIREMENTS                                               *vocal-requirements*

The following are required to use vocal.nvim:

- Neovim 0.11.0 or higher
- plenary.nvim library
- sox (Sound eXchange) for audio recording
- OpenAI API key

===============================================================================
3. INSTALLATION                                               *vocal-installation*

Using lazy.nvim:
>lua
    {
      "kyza/vocal.nvim",
      dependencies = {
        "nvim-lua/plenary.nvim",
      },
      config = function()
        require("vocal").setup({
          -- Your configuration here
        })
      end,
    }
<

===============================================================================
4. CONFIGURATION                                             *vocal-configuration*

vocal.nvim can be configured by passing a table to the setup function:
>lua
    require("vocal").setup({
      -- API key (string, table with command, or nil to use OPENAI_API_KEY env var)
      api_key = nil,
      
      -- Directory to save recordings
      recording_dir = os.getenv("HOME") .. "/recordings",
      
      -- Delete recordings after transcription
      delete_recordings = true,
      
      -- API configuration
      api = {
        model = "whisper-1",
        language = nil, -- Auto-detect language
        response_format = "json",
        temperature = 0,
        timeout = 60,
      },
    })
<

Configuration Options:                                     *vocal-config-options*

  api_key           (string|table|nil)  OpenAI API key, can be:
                    - nil: Will use OPENAI_API_KEY environment variable
                    - string: Direct API key
                    - table: Command to execute to retrieve the key
                    Example: {"pass", "show", "openai-api-key"}

  recording_dir     (string)            Directory to save audio recordings
                    Default: "$HOME/recordings"

  delete_recordings (boolean)           Whether to delete recordings after
                    transcription. Default: true

===============================================================================
5. USAGE                                                            *vocal-usage*

Basic workflow:

1. Start recording with the `:Vocal` command
2. Speak into your microphone
3. Press Enter to stop recording and transcribe
4. The transcribed text will be inserted at your cursor position

In visual mode, transcribed text will replace the selected text.

===============================================================================
6. COMMANDS                                                      *vocal-commands*

:Vocal                  Start or stop audio recording
                        When started, a popup will appear with instructions

:VocalDebug             Enable debug mode for troubleshooting
                        Creates a log file at ~/.cache/vocal.log

:VocalNoDebug           Disable debug mode

:VocalOpenLog           Open the debug log file

:VocalTestAPI           Test API connectivity with your configured API key

===============================================================================
7. API CONFIGURATION                                            *vocal-api-config*

Advanced API options can be configured in the api table:
>lua
    api = {
      model = "whisper-1",        -- Whisper model to use
      language = nil,             -- Language code or nil for auto-detection
      response_format = "json",   -- API response format
      temperature = 0,            -- Sampling temperature (0-1)
      timeout = 60,               -- Timeout in seconds
    }
<

===============================================================================
8. TROUBLESHOOTING                                         *vocal-troubleshooting*

Common issues:

- "sox is not installed": Install sox on your system
  - Ubuntu/Debian: sudo apt install sox
  - macOS: brew install sox
  - Windows: Install through chocolatey or directly

- "API key not found": Set your OpenAI API key in the configuration or
  as the OPENAI_API_KEY environment variable

- Recording issues: Check that your microphone is working and properly configured
  in your operating system

- For detailed logs: Run `:VocalDebug` to enable logging

===============================================================================
9. LICENSE                                                        *vocal-license*

MIT

===============================================================================
vim:tw=78:ts=8:ft=help:norl: