*vocal.txt*  Speech-to-text transcription using OpenAI Whisper API or local models

===============================================================================
CONTENTS                                                          *vocal-contents*

    1. Introduction .................... |vocal-introduction|
    2. Requirements .................... |vocal-requirements|
    3. Installation .................... |vocal-installation|
    4. Configuration ................... |vocal-configuration|
    5. Usage ........................... |vocal-usage|
    6. Commands ........................ |vocal-commands|
    7. Transcription Options ........... |vocal-transcription|
    8. Troubleshooting ................. |vocal-troubleshooting|
    9. License ......................... |vocal-license|

===============================================================================
1. INTRODUCTION                                               *vocal-introduction*

vocal.nvim is a lightweight Neovim plugin that provides speech-to-text
functionality using either the OpenAI Whisper API or local Whisper models.
It enables users to record audio directly within Neovim, transcribe it,
and insert the resulting text into the current buffer.

===============================================================================
2. REQUIREMENTS                                               *vocal-requirements*

The following are required to use vocal.nvim:

- Neovim 0.11.0 or higher
- plenary.nvim library
- sox (Sound eXchange) for audio recording

For API transcription:
- OpenAI API key

For local transcription:
- Python with the openai-whisper package installed (`pip install openai-whisper`)

===============================================================================
3. INSTALLATION                                               *vocal-installation*

Using lazy.nvim:
>lua
    {
      "kyza0d/vocal.nvim",
      dependencies = {
        "nvim-lua/plenary.nvim",
      },
      config = function()
        require("vocal").setup({
          -- Your configuration here
        })
      end,
    }
<

===============================================================================
4. CONFIGURATION                                             *vocal-configuration*

vocal.nvim can be configured by passing a table to the setup function:
>lua
    require("vocal").setup({
      -- API key (string, table with command, or nil to use OPENAI_API_KEY env var)
      api_key = nil,
      
      -- Directory to save recordings
      recording_dir = os.getenv("HOME") .. "/recordings",
      
      -- Delete recordings after transcription
      delete_recordings = true,
      
      -- Keybinding to trigger :Vocal (set to nil to disable)
      keymap = "<leader>v",
      
      -- Local model configuration (set this to use local model instead of API)
      local_model = {
        model = "base",         -- Model size: tiny, base, small, medium, large
        path = "~/whisper",     -- Path to download and store models
      },
      
      -- API configuration (used only when local_model is not set)
      api = {
        model = "whisper-1",
        language = nil,         -- Auto-detect language
        response_format = "json",
        temperature = 0,
        timeout = 60,
      },
    })
<

Configuration Options:                                     *vocal-config-options*

  api_key           (string|table|nil)  OpenAI API key, can be:
                    - nil: Will use OPENAI_API_KEY environment variable
                    - string: Direct API key
                    - table: Command to execute to retrieve the key
                    Example: {"pass", "show", "openai-api-key"}

  recording_dir     (string)            Directory to save audio recordings
                    Default: "$HOME/recordings"

  delete_recordings (boolean)           Whether to delete recordings after
                    transcription. Default: true

  keymap            (string|nil)        Keybinding to trigger the :Vocal command
                    Default: "<leader>v" (set to nil to disable)

  local_model       (table|nil)         Configuration for local Whisper model
                    Set to nil to use the OpenAI API instead

===============================================================================
5. USAGE                                                            *vocal-usage*

Basic workflow:

1. Start recording with the `:Vocal` command or configured keymap
2. Speak into your microphone
3. Run `:Vocal` again to stop recording and transcribe
4. The transcribed text will be inserted at your cursor position

In visual mode, transcribed text will replace the selected text.

===============================================================================
6. COMMANDS                                                      *vocal-commands*

:Vocal                  Start or stop audio recording and transcription
                        When started, a status indicator will show recording state
                        When stopped, the plugin will automatically transcribe the audio

===============================================================================
7. TRANSCRIPTION OPTIONS                                    *vocal-transcription*

vocal.nvim supports two methods of transcription:

1. OpenAI Whisper API (requires API key)
   Configure using the api table:
>lua
    api = {
      model = "whisper-1",        -- Whisper API model
      language = nil,             -- Language code or nil for auto-detection
      response_format = "json",   -- API response format
      temperature = 0,            -- Sampling temperature (0-1)
      timeout = 60,               -- Timeout in seconds
    }
<

2. Local Whisper Model (requires Python with openai-whisper package)
   Configure using the local_model table:
>lua
    local_model = {
      model = "base",             -- Model size: tiny, base, small, medium, large
      path = "~/whisper",         -- Path to download and store models
    }
<
   The local model will be automatically downloaded if not present.
   Model sizes and approximate memory requirements:
   - tiny: ~75MB
   - base: ~150MB
   - small: ~500MB
   - medium: ~1.5GB
   - large: ~3GB

===============================================================================
8. TROUBLESHOOTING                                         *vocal-troubleshooting*

Common issues:

- "sox is not installed": Install sox on your system
  - Ubuntu/Debian: sudo apt install sox
  - macOS: brew install sox
  - Windows: Install through chocolatey or directly

- "API key not found": Set your OpenAI API key in the configuration or
  as the OPENAI_API_KEY environment variable (only needed for API transcription)

- "Python package not found": Install the openai-whisper package with
  `pip install openai-whisper` (only needed for local transcription)

- Recording issues: Check that your microphone is working and properly configured
  in your operating system

===============================================================================
9. LICENSE                                                        *vocal-license*

MIT

===============================================================================
vim:tw=78:ts=8:ft=help:norl:
